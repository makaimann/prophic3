Abstraction Refinement Algorithm for IC3 via Implicit Predicate Abstraction for Array Transition Systems

Motivation and High Level Ideas:
This procedure seeks to improve IC3-based model checking for systems that contain arrays. One of the primary issues
in model checking with arrays is that quantifier-free interpolants for the theory of arrays are not guaranteed.
Furthermore, it is often the case that array axioms do not need to be instantiated for every possible value to prove
or disprove a given property. Thus, we propose an abstraction refinement loop that replaces the array with an unbounded
sort and array operators with uninterpreted functions. We then lazily instantiate array axioms over these uninterpreted
functions.

Sufficiently modeling arrays in a transition system might require more precision than we can achieve with only the indices
available in the transition system. Therefore, we also allow the procedure to dynamically introduce two types of variables:

1. Prophecy variables: these are symbolic, unchanging variables that can be used to "skolemize" a universally quantified
   variable in a property

   - We rely on Theorems 3 and 4 from Ken McMillan's Eager Abstraction for Symbolic Model Checking
     Theorem 4 allows us to introduce a universal quantifier for a property, phi: phi -> forall z = t . phi
     Theorem 3 allows us to replace the universally quantified variable, z, with a prophecy variable

     Thus, we have an axiom schemata that looks like: forall z = t . phi,
     where z does not appear in phi, and t occurs somewhere in the transition system

     to pick t, we look at the final state of the counter-example trace for an index that was assigned to
     the value we want to track (i.e. whichever concrete index was used to violate an array axiom). If we can
     find a symbolic index that had that value, then we set to that symbolic index

     Note: for performance reasons, we will likely not want to add every array axiom that is broken. We'll need
     a way of finding ones that actually impact the property

2. History variables: these are variables which can be added to the system to keep track of past values. These values can
   change temporally, but crucially they do not fall into the cone of influence of the original system. In other words,
   they only store information, they don't change the behavior of the system.


We believe that this abstraction refinement loop, coupled with the introduction of prophecy and history variables, is
sufficient to prove many properties. It might even be a complete approach.

At any given point in our procedure, our system should be an over-approximation of the original system and property. In
other words, if we prove the property then it holds, but counter-examples can be spurious. This is currently unproven,
but we have good reason to believe this is likely. Furthermore, we would like to show that the algorithm never gets "stuck",
in other words, the algorithm can always make a refinement step.

Outline of Algorithm Steps

This outline is approximately ordered, but cannot be translated directly to code yet. It is likely we will allow multiple
refinement steps at any given time and the choice of which refinement to apply is a heuristic. Of course, the refinements
will be guarded by some necessary preconditions.

Abstraction Steps

 1. Replace all arrays with an unconstrained variable with unbounded sort
    - it's crucial that is unconstrained so we don't accidentally overconstrain the system
    - similarly, the sort must be unbounded because we need to allow for an unbounded number of writes to the array
 2. Remove all writes to the array from the formula, but keep track of the write structure for use in the refinement step
 3. Replace all array reads with a binary uninterpreted function which takes the unbounded array sort and an index and
    returns something of the element sort
    - use a distinct read function for each array
 4. Replace all array equalities with a binary uninterpreted function which takes two of the unbounded array sorts and
    returns a bool

Refinement Steps

Repeat until convergence:

 1. Run IC3+IA
 2. If the property is proven, return TRUE
 3. Otherwise, examine the counter-example
 4. If the counter-example does not violate any array axioms, return the trace (might need to edit it) and FALSE
 5. Otherwise, add a constraint to the initial state, invariant or transition relation that rules out this counter-example
    - this involves analyzing the counter-example and "untiming" the array axiom so that it is fixed in the transition system
    Note: in general this might take more steps or involve adding history variables, but it is much simpler overall than adding
    temporal formulas to constrain the behavior (e.g. a read 10 steps later has the same value at a given index)


Note: as an optimization we should also consider adding multiple axioms in each refinement step
      The idea Ahmed sketched out (based on his NRA work) was to have a BMC query which is iteratively refined
      before returning to IC3+IA

Identifying array axiom violations:

We have a module which is fully aware of the array operations in the original system, including the initial state.
It can thus simulate the updates to the array based on the assignments to index variables and element variables. If
any of the array axioms are violated, we can figure out what went wrong.

We'll model the initial state as writes on a CONSTARRAY, but if the original initial state was unconstrained, then
we'll populate it with X. X is a "don't-care", meaning if we simulate the counter-example and have an X, it can be assigned
to any value in the abstract counter-example without violating an array axiom.

Whenever possible, we try to write lemmas over symbolic indices. Adding lemmas over interpreted constants is a last resort
and is hopefully not necessary very often (it's possible it's never necessary). Furthermore, we try refinements in two layers.
First, we try to apply axioms over one-step or two-steps of the transition system (e.g. adjacent unrolled symbols). For
arrays, this might not be enough to rule out counter-examples. If there are not any one-step or two-step axioms that will
rule out a given counter-example, we need to try a more advanced refinement such as adding a prophecy or history variable.

Types of violations and the resulting refinement step:

 1. Read at an index is incorrect in the initial state -> constrain the initial state at that index to be the correct value
    - we can also add lemmas relating arrays by relating their indices, e.g.
      if the original initial state was: mem1 = WRITE(CONSTARRAY(typeof(mem1), 0), 1, 2) and y=1 in the initial state,
      we can add:

      x != y -> read(mem1, x) = 0
      x  = y -> read(mem1, x) = 1

 2. Array was not updated correctly on a write -> add a constraint to the UF saying that the next memory provides a certain
    value at that index, e.g.

    if we had: next(mem1) = WRITE(mem1, x, val)
    we can then add

    read(next(mem1), x) = val

 3. An array value at an index was not maintained when it should have been

    There are two cases for this one:
    - One of the array indices is equal to the value we should have maintained at the time-step it was lost
        this is the simpler case and we can simply rule it out by adding a lemma

        say mem1 is updated by x and not y, but it lost it's value at y in the abstract counter-example
        Then we add:

        y != x -> read(next(mem1), y) = read(mem1, y) // the array maintains the value

    - None of the array indices in the transition system was equal to that concrete index value at the timestep it was lost
        this is a harder case and we have two possible solutions:
        1. introduce a history or prophecy variable to track that location
            - the prophecy variable is relevant if we need the array to maintain values at some symbolic index in the property
            - the history one is relevant if one of the indices *used* to have that value in a previous timestep
        2. add a lemma over an interpreted constant (e.g. 5) for that array
           this should be a last resort

 4. A universally quantified property is violated because in the assumptions it held, but then the index variable changed in the state update
    - instantiate a prophecy variable

 5. An equality relation doesn't produce the right value
    - this is trickier to maintain, because we also need to reason about the array initial values and possibly X values
      for example, if there's an X in each of the arrays at an index, it can always have found a way to be different

    4 cases:

      - equality in the transition system, add lemmas constraining the reads at various indices in the system to match
      - equality in the property, replace it with a prophecy variable saying that the arrays at that index agree on
         the value (quantified assertion)
      - disequality in the transition system, add a fresh symbol (that can change) which must result in different
         values when used as an index for these two arrays
      - disequality in the property, add lemmas axiomatizing array dis-equality, e.g.
         read(mem1, x) != read(mem2, x) -> !(equal(mem1, mem2))


Note: as we introduce prophecy variables for the indices, we can add array axioms over those prophecy variables.
      we can do the same for history variables, or we can even add prophecy variables for those history variables

      This comes from Theorem 4 of the Eager Abstraction paper,

      We transform property P, into forall x . x = t -> P

      where t is some term in the transition system, then we can replace the forall x with a prophecy variable.


General Ideas / Rules

Lemmas that involve a quantified variable use a prophecy variable and are added to the property
Lemmas that require an existential quantifer use a fresh index symbol and are added as an invariant


Possible preprocessing steps:

1. replace each write in nested writes on an array with a fresh array symbol and add an equality
   - this might simplify the counter-example analysis

   Example:

   started with: next(mem1) = WRITE(WRITE(mem1, idx1, val1), idx2, val2)

   ->: next(mem1) = WRITE(mem1_1, idx2, val2)
       mem1_1 = WRITE(mem1, idx1, val1)


Open Questions
 1. do we need history variables?
 2. if so, should they be simple delays or should they all store unique values? (e.g. the last two unique values of x)
 3. is this procedure complete?
 4. is the abstraction always an overapproximation?

